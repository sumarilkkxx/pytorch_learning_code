{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " from torch.utils.data import Dataset\n",
    " from PIL import Image\n",
    " import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"D:\\\\code_projects\\dataset\\hymenoptera_data\\\\train\\\\ants\\\\0013035.jpg\"\n",
    "img_test = Image.open(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查看图片的像素大小\n",
    "img_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示图片\n",
    "img_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Dataset in module torch.utils.data.dataset:\n",
      "\n",
      "class Dataset(typing.Generic)\n",
      " |  An abstract class representing a :class:`Dataset`.\n",
      " |  \n",
      " |  All datasets that represent a map from keys to data samples should subclass\n",
      " |  it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      " |  data sample for a given key. Subclasses could also optionally overwrite\n",
      " |  :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      " |  :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      " |  of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      " |  optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      " |  loading. This method accepts list of indices of samples of batch and returns\n",
      " |  list of samples.\n",
      " |  \n",
      " |  .. note::\n",
      " |    :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      " |    sampler that yields integral indices.  To make it work with a map-style\n",
      " |    dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Dataset\n",
      " |      typing.Generic\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __add__(self, other: 'Dataset[T_co]') -> 'ConcatDataset[T_co]'\n",
      " |  \n",
      " |  __getitem__(self, index) -> +T_co\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __orig_bases__ = (typing.Generic[+T_co],)\n",
      " |  \n",
      " |  __parameters__ = (+T_co,)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from typing.Generic:\n",
      " |  \n",
      " |  __class_getitem__(params) from builtins.type\n",
      " |  \n",
      " |  __init_subclass__(*args, **kwargs) from builtins.type\n",
      " |      This method is called when a class is subclassed.\n",
      " |      \n",
      " |      The default implementation does nothing. It may be\n",
      " |      overridden to extend subclasses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#关于Dataset的帮助文档\n",
    "help(Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSource:\u001b[0m        \n",
      "\u001b[1;32mclass\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGeneric\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;34mr\"\"\"An abstract class representing a :class:`Dataset`.\n",
      "\n",
      "    All datasets that represent a map from keys to data samples should subclass\n",
      "    it. All subclasses should overwrite :meth:`__getitem__`, supporting fetching a\n",
      "    data sample for a given key. Subclasses could also optionally overwrite\n",
      "    :meth:`__len__`, which is expected to return the size of the dataset by many\n",
      "    :class:`~torch.utils.data.Sampler` implementations and the default options\n",
      "    of :class:`~torch.utils.data.DataLoader`. Subclasses could also\n",
      "    optionally implement :meth:`__getitems__`, for speedup batched samples\n",
      "    loading. This method accepts list of indices of samples of batch and returns\n",
      "    list of samples.\n",
      "\n",
      "    .. note::\n",
      "      :class:`~torch.utils.data.DataLoader` by default constructs an index\n",
      "      sampler that yields integral indices.  To make it work with a map-style\n",
      "      dataset with non-integral indices/keys, a custom sampler must be provided.\n",
      "    \"\"\"\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT_co\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Subclasses of Dataset should implement __getitem__.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# def __getitems__(self, indices: List) -> List[T_co]:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# Not implemented to prevent false-positives in fetcher check in\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# torch.utils.data._utils.fetch._MapDatasetFetcher\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__add__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"Dataset[T_co]\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;34m\"ConcatDataset[T_co]\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
      "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mConcatDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# No `def __len__(self)` default?\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# See NOTE [ Lack of Default `__len__` in Python Abstract Base Classes ]\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;31m# in pytorch/torch/utils/data/sampler.py\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFile:\u001b[0m           d:\\anaconda\\envs\\pythorch\\lib\\site-packages\\torch\\utils\\data\\dataset.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     IterableDataset, TensorDataset, StackDataset, ConcatDataset, Subset, MapDataPipe"
     ]
    }
   ],
   "source": [
    "#对于Dataset的使用说明\n",
    "Dataset??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0013035.jpg'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#尝试使用相对路径读取文件地址\n",
    "path = \"../dataset/hymenoptera_data/train/ants\"\n",
    "image_path_list = os.listdir(path)\n",
    "# print(image_path_list)\n",
    "# image_path_list[-1]\n",
    "image_path_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个MyData的类，方便后续读取所有图片的文件地址从而创建初始数据集\n",
    "class MyData(Dataset):\n",
    "    def __init__(self, root_dir,label_dir):\n",
    "        #引入self，将变量变为全局变量，root_dir表示图像地址的上级地址，label_dir表示具体的图像名称地址\n",
    "        self.root_dir = root_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.file_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.img_path = os.listdir(self.file_path)    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #获取到每一个图片的文件路径，返回的是图片以及对应的图像标签\n",
    "        img_name = self.img_path[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.label_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        label = self.label_dir\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        #返回数据集的长度\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义各类图像文件的相对位置\n",
    "root_dir = \"../dataset/hymenoptera_data/train\"\n",
    "ants_label_dir = \"ants\" \n",
    "bees_label_dir = \"bees\"\n",
    "#创建两类图像的初始数据集\n",
    "ants_dataset = MyData(root_dir, ants_label_dir)\n",
    "bees_dataset = MyData(root_dir, bees_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试数据集是否创建成功\n",
    "ants_img_test, ants_label = ants_dataset[-1]\n",
    "ants_img_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试数据集是否创建成功\n",
    "bees_img_test, bees_label = bees_dataset[1]\n",
    "bees_img_test.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "245"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#合并两类子数据集，创建训练数据\n",
    "train_dataset = ants_dataset + bees_dataset\n",
    "train_img_test, train_label = train_dataset[0]\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "pandas.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
